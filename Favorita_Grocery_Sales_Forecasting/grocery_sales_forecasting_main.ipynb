{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grocery_sales_forecasting_Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import os.path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import supplementary visualizations code visuals.py\n",
    "#import visuals as vs\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load one year's train data;   \n",
    "Add oil price of corresponding date;  \n",
    "Add transaction of coresponding date and store;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Favorita grocery sales forecasting testing data has 3370464 samples with 5 features each.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6dfe58c1e67e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mdate_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mdate_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'store_nbr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_store_nbr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_nbr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_item_nbr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'unit_sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xuemeigao/anaconda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m/Users/xuemeigao/anaconda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    817\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid type comparison\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "years = [2013, 2014, 2015, 2016]\n",
    "\n",
    "#Load data\n",
    "# train_2013 = pickle.load(open( 'train_2013.pkl', \"rb\" ))\n",
    "# train_2014 = pickle.load(open( 'train_2014.pkl', \"rb\" ))\n",
    "# train_2015 = pickle.load(open( 'train_2015.pkl', \"rb\" ))\n",
    "# train_2016 = pickle.load(open( 'train_2016.pkl', \"rb\" ))\n",
    "# train_2017 = pickle.load(open( 'train_2017.pkl', \"rb\" ))\n",
    "# train_data = pd.concat([train_2013, train_2014, train_2015, train_2016, train_2017])\n",
    "\n",
    "test_data = pd.read_csv(\"input/test.csv\")\n",
    "print(\"Favorita grocery sales forecasting testing data has {} samples with {} features each.\".format(*test_data.shape))\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "\n",
    "for year in years:\n",
    "    pickle_file = 'train_' + str(year) + '_8.pkl'\n",
    "    train_data = pickle.load(open( pickle_file, \"rb\" ))\n",
    "    for item in range(test_data.shape[0]):\n",
    "        date_test = test_data.at[item, 'date']\n",
    "        test_store_nbr = test_data.at[item,'store_nbr']\n",
    "        test_item_nbr = test_data.at[item,'item_nbr']\n",
    "\n",
    "        date_hist = date_test.replace(year = year)\n",
    "        mask = (train_data['date']==date_hist)&(train_data['store_nbr'] == test_store_nbr)&(train_data['item_nbr'] == test_item_nbr)\n",
    "        result = train_data.loc[mask, 'unit_sales']\n",
    "        if result.shape[0]>0:\n",
    "            test_data.at[item, str(year)] = result.iloc[0]\n",
    "    print(year, 'is completed!')\n",
    "            \n",
    "# test_data.loc[:,['id','unit_sales']].to_csv('submission.csv', sep='\\t')\n",
    "test_data.to_csv('test_data.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load one year's train data;  \n",
    "train_pkl = 'train_2017.pkl'\n",
    "years = ['2013', '2014', '2015', '2016', '2017']\n",
    "train_data = pickle.load(open( train_pkl, \"rb\" ))\n",
    "\n",
    "#Add oil price of corresponding date; \n",
    "oil = pd.read_csv(\"input/oil.csv\")\n",
    "oil['date'] = pd.to_datetime(oil['date'], format='%Y-%m-%d')\n",
    "train_data= pd.merge(train_data,oil, right_on='date',left_on='date',how='left')\n",
    "\n",
    "#Add transaction of coresponding date and store;\n",
    "transactions = pd.read_csv(\"input/transactions.csv\")\n",
    "transactions['date'] = pd.to_datetime(transactions['date'], format='%Y-%m-%d')\n",
    "train_data= pd.merge(train_data,transactions, left_on=['date', 'store_nbr'], right_on=['date', 'store_nbr'], how='left')\n",
    "display(train_data.tail(5))\n",
    "display(train_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training feature and training target\n",
    "target_raw = train_data['unit_sales']\n",
    "features_raw = train_data.drop(['id', 'unit_sales'], axis=1)\n",
    "\n",
    "#Drop items with missing data\n",
    "features_raw.replace([\"NaN\", 'NaT'], np.nan, inplace = True)\n",
    "features_raw.dropna(inplace=True)\n",
    "# features_clean_NaN = features_raw[~features_raw.isin(['NaN', 'NaT']).any(axis=1)] #computationally expensive\n",
    "\n",
    "#Categorical feature\n",
    "features_raw['onpromotion'] = features_raw['onpromotion'].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "#Numerical feature\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler() # default=(0, 1)\n",
    "numerical = ['dcoilwtico', 'transactions']\n",
    "features_minmax_transform = pd.DataFrame(data = features_raw)\n",
    "features_minmax_transform[numerical] = scaler.fit_transform(features_minmax_transform[numerical])\n",
    "display(features_minmax_transform.tail(5))\n",
    "display(features_minmax_transform.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Model: Search the history record, and average it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
