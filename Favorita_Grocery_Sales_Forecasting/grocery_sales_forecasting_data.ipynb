{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Favorita: Favorita Grocery Sales Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration  \n",
    "For each data file, I want to see:  \n",
    "(1) some samples with display(df.head(5)) or display(df.tail(5))  \n",
    "(2) A summary of this DataFrame with df.describe()  \n",
    "(3) Check if there is missing data with df.isnull().values.any()  \n",
    "(4) The number of unique values for each variable with display(df['column_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import os.path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import supplementary visualizations code visuals.py\n",
    "#import visuals as vs\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def loaddata(filename, nrows=None):\n",
    "    types = {'id': 'int32', 'item_nbr': 'int32', 'store_nbr': 'int16', 'unit_sales': 'float32', 'onpromotion': bool,}\n",
    "    data = pd.read_csv(filename, parse_dates=['date'], dtype=types, nrows=nrows, infer_datetime_format=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adou/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2802: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset has 125497040 data points with 6 variables each.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>103665</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105575</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108786</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108797</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>108952</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>111397</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>114790</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       date  store_nbr  item_nbr  unit_sales onpromotion\n",
       "0   0 2013-01-01         25    103665         7.0         NaN\n",
       "1   1 2013-01-01         25    105574         1.0         NaN\n",
       "2   2 2013-01-01         25    105575         2.0         NaN\n",
       "3   3 2013-01-01         25    108079         1.0         NaN\n",
       "4   4 2013-01-01         25    108701         1.0         NaN\n",
       "5   5 2013-01-01         25    108786         3.0         NaN\n",
       "6   6 2013-01-01         25    108797         1.0         NaN\n",
       "7   7 2013-01-01         25    108952         1.0         NaN\n",
       "8   8 2013-01-01         25    111397        13.0         NaN\n",
       "9   9 2013-01-01         25    114790         3.0         NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "import sqlite3\n",
    "import sqlalchemy\n",
    "engine = sqlalchemy.create_engine('sqlite:///data/favorita.db')\n",
    "\n",
    "train_pkl = 'train_2017_8.csv'\n",
    "years = range(2013, 2018)\n",
    "months = range(1, 13)\n",
    "if not os.path.isfile(train_pkl):\n",
    "    train_data = loaddata('input/train.csv')\n",
    "    print(\"Training dataset has {} data points with {} variables each.\".format(*train_data.shape))\n",
    "#    train_data['date'] = pd.to_datetime(train_data['date'], format='%Y-%m-%d')\n",
    "#     train_data.to_sql('train', engine)\n",
    "    \n",
    "# save pickle file for each month\n",
    "    for year in years:\n",
    "#         for month in months:\n",
    "#             file_name = 'train_' + str(year) + '_' + str(month) + '.pkl'\n",
    "#             start = str(year) + '-' + str(month) + '-01'\n",
    "#             if month<12:\n",
    "#                 end = str(year) + '-' + str(month + 1) + '-01'\n",
    "#             else:\n",
    "#                 end = str(year + 1) + '-01-01'\n",
    "        file_name = 'train_' + str(year) + '_8.csv'\n",
    "        start = str(year) + '-08-16'\n",
    "        end = str(year) + '-08-31'\n",
    "\n",
    "        mask = (train_data['date']>=start)&(train_data['date']<=end)\n",
    "        train_data.loc[mask].to_csv(file_name) \n",
    "  \n",
    "# save pickle file for three even files\n",
    "#     one_third_index = int(train_data.shape[0] // 3)\n",
    "#     two_third_index = int(train_data.shape[0] * 2 // 3)\n",
    "#     #pickle can only dump a file with maximum size 2GB, so the train.cvs (5GB) is saved into 3 files\n",
    "#     pickle.dump(train_data.iloc[:one_third_index, :], open( \"train1.pkl\", \"wb\" ))\n",
    "#     pickle.dump(train_data.iloc[one_third_index:two_third_index, :], open( \"train2.pkl\", \"wb\" ))\n",
    "#     pickle.dump(train_data.iloc[two_third_index:, :], open( \"train3.pkl\", \"wb\" ))\n",
    "else:\n",
    "    train_data = pickle.load(open( train_pkl, \"rb\" ))\n",
    "    train_data['date'] = pd.to_datetime(train_data['date'], format='%Y-%m-%d')\n",
    "display(train_data.head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Train.csv\n",
    "Possilbe vales for each variable:\n",
    "onpromotion: [nan, False, True] (onpromotion is for a specified date and store_nbr), appoximatily 16% ot eh onpromotion values in this file is NaN.  \n",
    "train1.pkl (date range from 2013-01-01 to 2015-02-25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = train_data.shape[0]\n",
    "display(train_data.head(n=1))\n",
    "X_train_raw = train_data.drop(['unit_sales', 'id'], axis = 1, inplace = False)\n",
    "print(\"Favorita grocery sales forecasting has {} samples with {} features each.\".format(*X_train_raw.shape))\n",
    "X_train = X_train_raw.iloc[:num_samples, :]\n",
    "X_train.sort_values(['date'], ascending=True)\n",
    "display(X_train.head(5))\n",
    "display(X_train.tail(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2014 = pickle.load(open('train_2014.pkl', 'rb'))\n",
    "# train_2014.loc[(train_2014['onpromotion'] == True) | (train_2014['onpromotion'] == False)]\n",
    "train_2014.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. holidays_events.csv  \n",
    "1. data:\n",
    "2. type: ['Holiday', 'Transfer', 'Additional', 'Bridge', 'Work Day', 'Event']\n",
    "3. locale: ['Local', 'Regional', 'National']\n",
    "4. locale_name: ['Manta', 'Cotopaxi', 'Cuenca', 'Libertad', 'Riobamba', 'Puyo','Guaranda', 'Imbabura', 'Latacunga', 'Machala', 'Santo Domingo','El Carmen', 'Cayambe', 'Esmeraldas', 'Ecuador', 'Ambato', 'Ibarra','Quevedo', 'Santo Domingo de los Tsachilas', 'Santa Elena', 'Quito','Loja', 'Salinas', 'Guayaquil']\n",
    "5. description:\n",
    "6. transferred: [False,  True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_events = pd.read_csv(\"input/holidays_events.csv\")\n",
    "display(holidays_events.describe())\n",
    "display(holidays_events.head(n=1))\n",
    "#display(holidays_events['transferred'].unique())\n",
    "holidays_events.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. stores.csv  \n",
    "1. store_nbr: [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]\n",
    "2. city: ['Quito', 'Santo Domingo', 'Cayambe', 'Latacunga', 'Riobamba', 'Ibarra', 'Guaranda', 'Puyo', 'Ambato', 'Guayaquil', 'Salinas', 'Daule', 'Babahoyo', 'Quevedo', 'Playas', 'Libertad', 'Cuenca', 'Loja', 'Machala', 'Esmeraldas', 'Manta', 'El Carmen']\n",
    "3. state: ['Pichincha', 'Santo Domingo de los Tsachilas', 'Cotopaxi', 'Chimborazo', 'Imbabura', 'Bolivar', 'Pastaza', 'Tungurahua', 'Guayas', 'Santa Elena', 'Los Rios', 'Azuay', 'Loja', 'El Oro', 'Esmeraldas', 'Manabi']\n",
    "4. type: ['D', 'B', 'C', 'E', 'A']\n",
    "5. cluster: [13,  8,  9,  4,  6, 15,  7,  3, 12, 16,  1, 10,  2,  5, 11, 14, 17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stores = pd.read_csv(\"input/stores.csv\")\n",
    "display(stores.describe())\n",
    "display(stores.head(n=1))\n",
    "display(stores['cluster'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. oil.csv\n",
    "dcoilwtico: continuous value from 26.19~110.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oil = pd.read_csv(\"input/oil.csv\")\n",
    "oil['date'] = pd.to_datetime(oil['date'], format='%Y-%m-%d')\n",
    "display(oil.describe())\n",
    "# display(oil.head(n=5))\n",
    "train_data= pd.merge(train_data,oil, right_on='date',left_on='date',how='left')\n",
    "display(train_data.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. transactions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "stores_nbr = random.sample(range(1,54), 5)\n",
    "transactions = pd.read_csv(\"input/transactions.csv\")\n",
    "transactions['date'] = pd.to_datetime(transactions['date'], format='%Y-%m-%d')\n",
    "display(transactions.describe())\n",
    "display(transactions.head(n=1))\n",
    "train_data= pd.merge(train_data,transactions, left_on=['date', 'store_nbr'], right_on=['date', 'store_nbr'], how='left')\n",
    "display(train_data.tail(5))\n",
    "\n",
    "# for i_store in range(len(stores_nbr)):\n",
    "#     fig = plt.figure(figsize=(10, 15))\n",
    "#     for i in range(len(years)):\n",
    "#         start = years[i] + '-01-01'\n",
    "#         end = years[i] + '-12-31'\n",
    "#         mask = (transactions['date']>start)&(transactions['date']<=end) & (transactions['store_nbr'] == stores_nbr[i_store])\n",
    "#         ax = fig.add_subplot(1, len(years), i+1)\n",
    "#         #plt.figure(i_store)\n",
    "#         specific_store_year = transactions['transactions'][mask]\n",
    "#         plt.plot(range(len(specific_store_year)), specific_store_year)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. items.csv\n",
    "1. item_nbr: 4100 discrete values\n",
    "2. class: 337 discrete values\n",
    "3. perishable: continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"input/items.csv\")\n",
    "display(items.describe())\n",
    "display(items.head(n=5))\n",
    "display(items.sample(6))\n",
    "\n",
    "train_data= pd.merge(train_data,items, right_on='item_nbr',left_on='item_nbr',how='left')\n",
    "display(train_data.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"input/test.csv\")\n",
    "print(\"Favorita grocery sales forecasting testing data has {} samples with {} features each.\".format(*test_data.shape))\n",
    "test_data['date'] = pd.to_datetime(test_data['date'])\n",
    "test_data.sort_values('date', ascending=True)\n",
    "display(test_data.head(5))\n",
    "display(test_data.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sample_submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"input/sample_submission.csv\")\n",
    "display(sample_submission.head(n=5))\n",
    "sample_submission.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
